{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re, os, string\n",
    "from functools import reduce\n",
    "from math import log\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (16, 4)\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF** is useful for clustering tasks, like a document clustering or in other words, tf-idf can help you understand what kind of document you got now. **Term Frequency-Inverse Document Frequency (TF-IDF)** is a numerical statistic that demonstrates how important a word is to a corpus.\n",
    "\n",
    "**Term Frequency (TF)** is just ratio number of current word to the number of all words in document/string/etc.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1O_feq-LV4YxxPFGIZCGU-wBy1HaeouUY\" />\n",
    "Frequency of term t_i, where n_t — the number of t_i in current document/string, the sum of n_k is the number of all terms in current document/string.\n",
    "\n",
    "**Inverse Document Frequency (IDF)** is a log of the ratio of the number of all documents/string in the corpus to the number of documents with term t_i.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1vweCJa83sy3CkfmOmz71uKO4B-obJLMz\" />\n",
    "\n",
    "tf-idf(t, d, D) is the product tf(t, d) to idf(t, D).\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1wAjC0oJNkNAylEsyAZNmpopLxr8lmRHJ\" />\n",
    "If you want more theoretic information about TF-IDF I want advice you read publication on Wikipedia about it or read NLP Stanford post.\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a very simple example of 3 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simple example with Cats and Mouse',\n",
       " 'Another simple example with dogs and cats',\n",
       " 'Another simple example with mouse and cheese']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"\n",
    "Simple example with Cats and Mouse\n",
    "Another simple example with dogs and cats\n",
    "Another simple example with mouse and cheese\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that lets make bags of words for our corpus and for every string too. But before we have to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line A:  ['simple', 'example', 'with', 'cats', 'and', 'mouse']\n",
      "Line B:  ['another', 'simple', 'example', 'with', 'dogs', 'and', 'cats']\n",
      "Line C:  ['another', 'simple', 'example', 'with', 'mouse', 'and', 'cheese']\n",
      "Word Set:  {'simple', 'another', 'cheese', 'example', 'cats', 'and', 'with', 'mouse', 'dogs'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>cheese</th>\n",
       "      <th>dogs</th>\n",
       "      <th>example</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  another  cats  cheese  dogs  example  mouse  simple  with\n",
       "0    1        0     1       0     0        1      1       1     1\n",
       "1    1        1     1       0     1        1      0       1     1\n",
       "2    1        1     0       1     0        1      1       1     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "print('Line A: ', l_A)\n",
    "print('Line B: ', l_B)\n",
    "print('Line C: ', l_C)\n",
    "\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "print('Word Set: ', word_set)\n",
    "\n",
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "\n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "\n",
    "for word in l_C:\n",
    "    word_dict_C[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict_A, word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the term frequency, the simplest choice is to use the raw count of a term in a string. For calculating tf for all terms, we must fill a dictionary as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>cheese</th>\n",
       "      <th>dogs</th>\n",
       "      <th>example</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   another      cats    cheese      dogs   example     mouse  \\\n",
       "0  0.166667  0.000000  0.166667  0.000000  0.000000  0.166667  0.166667   \n",
       "1  0.142857  0.142857  0.142857  0.000000  0.142857  0.142857  0.000000   \n",
       "2  0.142857  0.142857  0.000000  0.142857  0.000000  0.142857  0.142857   \n",
       "\n",
       "     simple      with  \n",
       "0  0.166667  0.166667  \n",
       "1  0.142857  0.142857  \n",
       "2  0.142857  0.142857  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf\n",
    "\n",
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_C = compute_tf(word_dict_C, l_C)\n",
    "pd.DataFrame([tf_A, tf_B, tf_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idf is a measure of how much information the token or word in our case, provides. For calculating idf we need fill dict too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheese</th>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cats</th>\n",
       "      <td>0.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>0.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs</th>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              idf\n",
       "simple   0.000000\n",
       "another  0.405465\n",
       "cheese   1.098612\n",
       "example  0.000000\n",
       "cats     0.405465\n",
       "and      0.000000\n",
       "with     0.000000\n",
       "mouse    0.405465\n",
       "dogs     1.098612"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = log(n / float(v))\n",
    "    return idf\n",
    "\n",
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])\n",
    "pd.DataFrame.from_dict(idf, orient='index', columns=['idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, tf-idf is the product of tf to idf. For our python example, tf-idf is dictionary with the corresponding products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF bag of words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>cheese</th>\n",
       "      <th>dogs</th>\n",
       "      <th>example</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and   another      cats    cheese      dogs  example     mouse  simple  \\\n",
       "0  0.0  0.000000  0.067578  0.000000  0.000000      0.0  0.067578     0.0   \n",
       "1  0.0  0.057924  0.057924  0.000000  0.156945      0.0  0.000000     0.0   \n",
       "2  0.0  0.057924  0.000000  0.156945  0.000000      0.0  0.057924     0.0   \n",
       "\n",
       "   with  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf\n",
    "\n",
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)\n",
    "\n",
    "print('TF-IDF bag of words:')\n",
    "pd.DataFrame([tf_idf_A, tf_idf_B, tf_idf_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can clearly see the difference between the original bag of words and the new bag of words with tf-idf weights. For example ‘dogs’, ‘cats’ and ‘mouse’ is important words, but word ‘and’ is not important, because this word is in all the strings and we can’t understand what is a string by the word ‘and’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original bag of words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>cheese</th>\n",
       "      <th>dogs</th>\n",
       "      <th>example</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  another  cats  cheese  dogs  example  mouse  simple  with\n",
       "0    1        0     1       0     0        1      1       1     1\n",
       "1    1        1     1       0     1        1      0       1     1\n",
       "2    1        1     0       1     0        1      1       1     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original bag of words:')\n",
    "pd.DataFrame([word_dict_A, word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we understand how TF-IDF works, the time has come for real example of clustering with TF-IDF weights. For real life, we can use scikit-learn implementation of TF-IDF and KMeans and suggest to use implementations from scikit-learn or from another popular libraries or frameworks because it’s reducing a number of potential errors in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google and Facebook are strangling the free press to death. Democracy is the loser',\n",
       " \"Your 60-second guide to security stuff Google touted today at Next '18\",\n",
       " 'A Guide to Using Android Without Selling Your Soul to Google',\n",
       " 'Review: Lenovo’s Google Smart Display is pretty and intelligent',\n",
       " 'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is',\n",
       " 'Android is better than IOS',\n",
       " 'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency',\n",
       " 'is a numerical statistic that is intended to reflect',\n",
       " 'how important a word is to a document in a collection or corpus.',\n",
       " 'It is often used as a weighting factor in searches of information retrieval',\n",
       " 'text mining, and user modeling. The tf-idf value increases proportionally',\n",
       " 'to the number of times a word appears in the document',\n",
       " 'and is offset by the frequency of the word in the corpus']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>60</th>\n",
       "      <th>and</th>\n",
       "      <th>android</th>\n",
       "      <th>appears</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>at</th>\n",
       "      <th>better</th>\n",
       "      <th>by</th>\n",
       "      <th>coast</th>\n",
       "      <th>collection</th>\n",
       "      <th>corpus</th>\n",
       "      <th>death</th>\n",
       "      <th>democracy</th>\n",
       "      <th>display</th>\n",
       "      <th>document</th>\n",
       "      <th>facebook</th>\n",
       "      <th>factor</th>\n",
       "      <th>for</th>\n",
       "      <th>free</th>\n",
       "      <th>frequency</th>\n",
       "      <th>google</th>\n",
       "      <th>greece</th>\n",
       "      <th>guide</th>\n",
       "      <th>how</th>\n",
       "      <th>idf</th>\n",
       "      <th>important</th>\n",
       "      <th>in</th>\n",
       "      <th>increases</th>\n",
       "      <th>information</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>intended</th>\n",
       "      <th>inverse</th>\n",
       "      <th>ios</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>knows</th>\n",
       "      <th>lenovo</th>\n",
       "      <th>loser</th>\n",
       "      <th>maps</th>\n",
       "      <th>mining</th>\n",
       "      <th>modeling</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>next</th>\n",
       "      <th>no</th>\n",
       "      <th>number</th>\n",
       "      <th>numerical</th>\n",
       "      <th>object</th>\n",
       "      <th>of</th>\n",
       "      <th>off</th>\n",
       "      <th>offset</th>\n",
       "      <th>often</th>\n",
       "      <th>one</th>\n",
       "      <th>or</th>\n",
       "      <th>press</th>\n",
       "      <th>pretty</th>\n",
       "      <th>proportionally</th>\n",
       "      <th>reflect</th>\n",
       "      <th>retrieval</th>\n",
       "      <th>review</th>\n",
       "      <th>searches</th>\n",
       "      <th>second</th>\n",
       "      <th>security</th>\n",
       "      <th>selling</th>\n",
       "      <th>short</th>\n",
       "      <th>smart</th>\n",
       "      <th>soul</th>\n",
       "      <th>spots</th>\n",
       "      <th>statistic</th>\n",
       "      <th>strangling</th>\n",
       "      <th>stuff</th>\n",
       "      <th>submerged</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>than</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>to</th>\n",
       "      <th>today</th>\n",
       "      <th>touted</th>\n",
       "      <th>used</th>\n",
       "      <th>user</th>\n",
       "      <th>using</th>\n",
       "      <th>value</th>\n",
       "      <th>weighting</th>\n",
       "      <th>what</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171654</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159890</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.219885</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.175671</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         18        60       and   android  appears       are   as        at  \\\n",
       "0  0.000000  0.000000  0.189681  0.000000      0.0  0.302486  0.0  0.000000   \n",
       "1  0.298662  0.298662  0.000000  0.000000      0.0  0.000000  0.0  0.298662   \n",
       "2  0.000000  0.000000  0.000000  0.305934      0.0  0.000000  0.0  0.000000   \n",
       "3  0.000000  0.000000  0.236572  0.000000      0.0  0.000000  0.0  0.000000   \n",
       "4  0.000000  0.000000  0.159890  0.000000      0.0  0.000000  0.0  0.000000   \n",
       "\n",
       "   better   by     coast  collection  corpus     death  democracy   display  \\\n",
       "0     0.0  0.0  0.000000         0.0     0.0  0.302486   0.302486  0.000000   \n",
       "1     0.0  0.0  0.000000         0.0     0.0  0.000000   0.000000  0.000000   \n",
       "2     0.0  0.0  0.000000         0.0     0.0  0.000000   0.000000  0.000000   \n",
       "3     0.0  0.0  0.000000         0.0     0.0  0.000000   0.000000  0.377265   \n",
       "4     0.0  0.0  0.254979         0.0     0.0  0.000000   0.000000  0.000000   \n",
       "\n",
       "   document  facebook  factor  for      free  frequency    google    greece  \\\n",
       "0       0.0  0.302486     0.0  0.0  0.302486        0.0  0.189681  0.000000   \n",
       "1       0.0  0.000000     0.0  0.0  0.000000        0.0  0.187283  0.000000   \n",
       "2       0.0  0.000000     0.0  0.0  0.000000        0.0  0.222462  0.000000   \n",
       "3       0.0  0.000000     0.0  0.0  0.000000        0.0  0.236572  0.000000   \n",
       "4       0.0  0.000000     0.0  0.0  0.000000        0.0  0.159890  0.254979   \n",
       "\n",
       "      guide  how  idf  important   in  increases  information  intelligent  \\\n",
       "0  0.000000  0.0  0.0        0.0  0.0        0.0          0.0     0.000000   \n",
       "1  0.257555  0.0  0.0        0.0  0.0        0.0          0.0     0.000000   \n",
       "2  0.305934  0.0  0.0        0.0  0.0        0.0          0.0     0.000000   \n",
       "3  0.000000  0.0  0.0        0.0  0.0        0.0          0.0     0.377265   \n",
       "4  0.000000  0.0  0.0        0.0  0.0        0.0          0.0     0.000000   \n",
       "\n",
       "   intended  inverse  ios        is        it     knows    lenovo     loser  \\\n",
       "0       0.0      0.0  0.0  0.148048  0.000000  0.000000  0.000000  0.302486   \n",
       "1       0.0      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2       0.0      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3       0.0      0.0  0.0  0.184647  0.000000  0.000000  0.377265  0.000000   \n",
       "4       0.0      0.0  0.0  0.124796  0.219885  0.254979  0.000000  0.000000   \n",
       "\n",
       "       maps  mining  modeling  mysterious      next        no  number  \\\n",
       "0  0.000000     0.0       0.0    0.000000  0.000000  0.000000     0.0   \n",
       "1  0.000000     0.0       0.0    0.000000  0.298662  0.000000     0.0   \n",
       "2  0.000000     0.0       0.0    0.000000  0.000000  0.000000     0.0   \n",
       "3  0.000000     0.0       0.0    0.000000  0.000000  0.000000     0.0   \n",
       "4  0.254979     0.0       0.0    0.254979  0.000000  0.254979     0.0   \n",
       "\n",
       "   numerical    object        of       off  offset  often       one   or  \\\n",
       "0        0.0  0.000000  0.000000  0.000000     0.0    0.0  0.000000  0.0   \n",
       "1        0.0  0.000000  0.000000  0.000000     0.0    0.0  0.000000  0.0   \n",
       "2        0.0  0.000000  0.000000  0.000000     0.0    0.0  0.000000  0.0   \n",
       "3        0.0  0.000000  0.000000  0.000000     0.0    0.0  0.000000  0.0   \n",
       "4        0.0  0.254979  0.175671  0.254979     0.0    0.0  0.254979  0.0   \n",
       "\n",
       "      press    pretty  proportionally  reflect  retrieval    review  searches  \\\n",
       "0  0.302486  0.000000             0.0      0.0        0.0  0.000000       0.0   \n",
       "1  0.000000  0.000000             0.0      0.0        0.0  0.000000       0.0   \n",
       "2  0.000000  0.000000             0.0      0.0        0.0  0.000000       0.0   \n",
       "3  0.000000  0.377265             0.0      0.0        0.0  0.377265       0.0   \n",
       "4  0.000000  0.000000             0.0      0.0        0.0  0.000000       0.0   \n",
       "\n",
       "     second  security   selling  short     smart      soul     spots  \\\n",
       "0  0.000000  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "1  0.298662  0.298662  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.354763    0.0  0.000000  0.354763  0.000000   \n",
       "3  0.000000  0.000000  0.000000    0.0  0.377265  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000    0.0  0.000000  0.000000  0.254979   \n",
       "\n",
       "   statistic  strangling     stuff  submerged  term  text   tf  tfidf  than  \\\n",
       "0        0.0    0.302486  0.000000   0.000000   0.0   0.0  0.0    0.0   0.0   \n",
       "1        0.0    0.000000  0.298662   0.000000   0.0   0.0  0.0    0.0   0.0   \n",
       "2        0.0    0.000000  0.000000   0.000000   0.0   0.0  0.0    0.0   0.0   \n",
       "3        0.0    0.000000  0.000000   0.000000   0.0   0.0  0.0    0.0   0.0   \n",
       "4        0.0    0.000000  0.000000   0.254979   0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "   that       the  times        to     today    touted  used      user  \\\n",
       "0   0.0  0.379362    0.0  0.173853  0.000000  0.000000   0.0  0.000000   \n",
       "1   0.0  0.000000    0.0  0.171654  0.298662  0.298662   0.0  0.000000   \n",
       "2   0.0  0.000000    0.0  0.407796  0.000000  0.000000   0.0  0.000000   \n",
       "3   0.0  0.000000    0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n",
       "4   0.0  0.159890    0.0  0.000000  0.000000  0.000000   0.0  0.219885   \n",
       "\n",
       "      using  value  weighting      what   without  word      your  \n",
       "0  0.000000    0.0        0.0  0.000000  0.000000   0.0  0.000000  \n",
       "1  0.000000    0.0        0.0  0.000000  0.000000   0.0  0.257555  \n",
       "2  0.354763    0.0        0.0  0.000000  0.354763   0.0  0.305934  \n",
       "3  0.000000    0.0        0.0  0.000000  0.000000   0.0  0.000000  \n",
       "4  0.000000    0.0        0.0  0.254979  0.000000   0.0  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)\n",
    "\n",
    "feat_names = [string for string in tfidf_vectorizer.get_feature_names()]\n",
    "tfidf_dataframe = pd.DataFrame(tfidf.todense(), columns=feat_names)\n",
    "tfidf_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters).fit(tfidf)\n",
    "clusters = kmeans.labels_.tolist()\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: ['the', 'in', 'word', 'document', 'frequency', 'of', 'corpus', 'or', 'idf', 'tf', 'information', 'retrieval', 'is', 'to', 'and', 'collection', 'important', 'how', 'times', 'appears']\n",
      "\n",
      "Cluster 1 words: ['is', 'google', 'to', 'android', 'and', 'guide', 'your', 'the', 'better', 'than', 'ios', 'reflect', 'numerical', 'that', 'intended', 'statistic', 'lenovo', 'review', 'smart', 'intelligent']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words: \" % i, end='')\n",
    "    cluster_words = []\n",
    "    \n",
    "    for ind in order_centroids[i, :20]:\n",
    "        cluster_words.append(feat_names[ind])\n",
    "    \n",
    "    print(cluster_words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google and Facebook are strangling the free pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your 60-second guide to security stuff Google ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Guide to Using Android Without Selling Your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review: Lenovo’s Google Smart Display is prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google Maps user spots mysterious object subme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android is better than IOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In information retrieval, tf–idf or TFIDF, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is a numerical statistic that is intended to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how important a word is to a document in a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is often used as a weighting factor in sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text mining, and user modeling. The tf-idf val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to the number of times a word appears in the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and is offset by the frequency of the word in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1  Google and Facebook are strangling the free pr...\n",
       "1  Your 60-second guide to security stuff Google ...\n",
       "1  A Guide to Using Android Without Selling Your ...\n",
       "1  Review: Lenovo’s Google Smart Display is prett...\n",
       "1  Google Maps user spots mysterious object subme...\n",
       "1                         Android is better than IOS\n",
       "0  In information retrieval, tf–idf or TFIDF, sho...\n",
       "1  is a numerical statistic that is intended to r...\n",
       "0  how important a word is to a document in a col...\n",
       "0  It is often used as a weighting factor in sear...\n",
       "0  text mining, and user modeling. The tf-idf val...\n",
       "0  to the number of times a word appears in the d...\n",
       "0  and is offset by the frequency of the word in ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(all_text, index = [clusters], columns = ['text'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_for_predicting = [\"tf and idf is awesome!\", \"some androids is there\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification & Text Clustering\n",
    "Text classification is a problem where we have fixed set of classes/categories and any given text is assigned to one of these categories. In contrast, Text clustering is the task of grouping a set of unlabeled texts in such a way that texts in the same group (called a cluster) are more similar to each other than to those in other clusters.\n",
    "\n",
    "Let's implement the above two tasks using well-known machine algorithms: K-NN and K-Means respectively. Based on the implementation let's see whether both algorithms co-relate to each other or represent the same information.\n",
    "\n",
    "For training K-NN and K-Means models, we will be using 30 sentences which were collected from 3 categories, namely Cricket, Artificial Intelligence and Chemistry. These 30 sentences are stored in a text file which we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cricket is a bat and ball game played between...</td>\n",
       "      <td>Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Each phase of play is called an innings durin...</td>\n",
       "      <td>Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial intelligence is intelligence exhib...</td>\n",
       "      <td>Artifical Intillengence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the field of AI research defines itself as th...</td>\n",
       "      <td>Artifical Intillengence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A compound is a pure chemical substance compo...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence                    Label\n",
       "0   Cricket is a bat and ball game played between...                  Cricket\n",
       "1   Each phase of play is called an innings durin...                  Cricket\n",
       "2   Artificial intelligence is intelligence exhib...  Artifical Intillengence\n",
       "3   the field of AI research defines itself as th...  Artifical Intillengence\n",
       "4   A compound is a pure chemical substance compo...                Chemistry"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"train_sentences.csv\"\n",
    "train_lines_df = pd.read_csv(train_file)\n",
    "train_lines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cricket                    10\n",
       "Chemistry                  10\n",
       "Artifical Intillengence    10\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed  \n",
    "def clean(input_line):\n",
    "    stop_free = \" \".join([i for i in input_line.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    final_line = processed.split()\n",
    "    return final_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Cleaned_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cricket is a bat and ball game played between...</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>cricket bat ball game played two team eleven p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Each phase of play is called an innings durin...</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>phase play called inning one team bat attempti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial intelligence is intelligence exhib...</td>\n",
       "      <td>Artifical Intillengence</td>\n",
       "      <td>artificial intelligence intelligence exhibited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the field of AI research defines itself as th...</td>\n",
       "      <td>Artifical Intillengence</td>\n",
       "      <td>field ai research defines study intelligent ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A compound is a pure chemical substance compo...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>compound pure chemical substance composed one ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence                    Label  \\\n",
       "0   Cricket is a bat and ball game played between...                  Cricket   \n",
       "1   Each phase of play is called an innings durin...                  Cricket   \n",
       "2   Artificial intelligence is intelligence exhib...  Artifical Intillengence   \n",
       "3   the field of AI research defines itself as th...  Artifical Intillengence   \n",
       "4   A compound is a pure chemical substance compo...                Chemistry   \n",
       "\n",
       "                                    Cleaned_Sentence  \n",
       "0  cricket bat ball game played two team eleven p...  \n",
       "1  phase play called inning one team bat attempti...  \n",
       "2  artificial intelligence intelligence exhibited...  \n",
       "3  field ai research defines study intelligent ag...  \n",
       "4  compound pure chemical substance composed one ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_sentences = []\n",
    "for line in train_lines_df['Sentence'].values:\n",
    "    line = line.strip()\n",
    "    cleaned = clean(line)\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    train_clean_sentences.append(cleaned)\n",
    "\n",
    "train_lines_df['Cleaned_Sentence'] = train_clean_sentences\n",
    "train_lines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Cricket', 'Artifical Intillengence', 'Chemistry'], dtype='object')\n",
      "[0 1 2]\n",
      "length of salary slabs:  3\n"
     ]
    }
   ],
   "source": [
    "target_label = train_lines_df['Label']\n",
    "\n",
    "# Preparing target labels\n",
    "label_factor = pd.factorize(target_label)\n",
    "target_label_class = label_factor[0]\n",
    "label_definitions = label_factor[1]\n",
    "\n",
    "label_range = len(label_definitions)\n",
    "reversefactor = dict(zip(range(label_range), label_definitions))\n",
    "\n",
    "print(label_definitions)\n",
    "print(np.unique(target_label_class))\n",
    "print('length of salary slabs: ', label_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for model\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer.fit(train_lines_df['Cleaned_Sentence'])\n",
    "X_feat_names = [string for string in vectorizer.get_feature_names()]\n",
    "X_train = pd.DataFrame(vectorizer.transform(train_lines_df['Cleaned_Sentence']).todense(), columns=X_feat_names)\n",
    "\n",
    "y = target_label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering the document with KNN classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=200,\n",
       "    n_clusters=3, n_init=100, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering the training 30 sentences with K-means technique\n",
    "num_clusters = 3\n",
    "model_kmeans = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=200, n_init=100)\n",
    "model_kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: ['team', 'run', 'ball', 'inning', 'bat', 'score', 'batsman', 'cricket', 'opponent', 'main']\n",
      "\n",
      "Cluster 1 words: ['property', 'chemical', 'element', 'atom', 'substance', 'chemistry', 'electron', 'called', 'science', 'compound']\n",
      "\n",
      "Cluster 2 words: ['intelligence', 'machine', 'ai', 'intelligent', 'success', 'human', 'computer', 'learning', 'research', 'artificial']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_centroids = model_kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words: \" % i, end='')\n",
    "    cluster_words = []\n",
    "    \n",
    "    for ind in order_centroids[i, :10]:\n",
    "        cluster_words.append(X_feat_names[ind])\n",
    "    \n",
    "    print(cluster_words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the words related to cluster we can infer that, **Cluster 0 = Criket, Cluster 1 = Chemistry & Cluster 2 = Artificial Intelligence.** However, the labelling notations might change whenver we train the models but clusters will remain same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these based on the cluster data and notations\n",
    "cluster_label_map = {0: 'Cricket', 1: 'Chemistry', 2: 'Artificial Intelligence'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical compunds are used for preparing bombs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cricket is a boring game where the batsman onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning is an area of Artificial inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  Chemical compunds are used for preparing bombs...\n",
       "1  Cricket is a boring game where the batsman onl...\n",
       "2  Machine learning is an area of Artificial inte..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"test_sentences.csv\"\n",
    "test_lines_df = pd.read_csv(test_file)\n",
    "test_lines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Cleaned_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical compunds are used for preparing bombs...</td>\n",
       "      <td>chemical compunds used preparing bomb based re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cricket is a boring game where the batsman onl...</td>\n",
       "      <td>cricket boring game batsman enjoys game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning is an area of Artificial inte...</td>\n",
       "      <td>machine learning area artificial intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Chemical compunds are used for preparing bombs...   \n",
       "1  Cricket is a boring game where the batsman onl...   \n",
       "2  Machine learning is an area of Artificial inte...   \n",
       "\n",
       "                                    Cleaned_Sentence  \n",
       "0  chemical compunds used preparing bomb based re...  \n",
       "1            cricket boring game batsman enjoys game  \n",
       "2      machine learning area artificial intelligence  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_sentences = []\n",
    "for line in test_lines_df['Sentence'].values:\n",
    "    line = line.strip()\n",
    "    cleaned = clean(line)\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    test_clean_sentences.append(cleaned)\n",
    "\n",
    "test_lines_df['Cleaned_Sentence'] = test_clean_sentences\n",
    "test_lines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(vectorizer.transform(test_lines_df['Cleaned_Sentence']).todense(), columns=X_feat_names)\n",
    "\n",
    "pred_knn = model_knn.predict(X_test)\n",
    "pred_kmeans = model_kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Cleaned_Sentence</th>\n",
       "      <th>pred_knn</th>\n",
       "      <th>pred_kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical compunds are used for preparing bombs...</td>\n",
       "      <td>chemical compunds used preparing bomb based re...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cricket is a boring game where the batsman onl...</td>\n",
       "      <td>cricket boring game batsman enjoys game</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>Cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning is an area of Artificial inte...</td>\n",
       "      <td>machine learning area artificial intelligence</td>\n",
       "      <td>Artifical Intillengence</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Chemical compunds are used for preparing bombs...   \n",
       "1  Cricket is a boring game where the batsman onl...   \n",
       "2  Machine learning is an area of Artificial inte...   \n",
       "\n",
       "                                    Cleaned_Sentence                 pred_knn  \\\n",
       "0  chemical compunds used preparing bomb based re...                Chemistry   \n",
       "1            cricket boring game batsman enjoys game                  Cricket   \n",
       "2      machine learning area artificial intelligence  Artifical Intillengence   \n",
       "\n",
       "               pred_kmeans  \n",
       "0                Chemistry  \n",
       "1                  Cricket  \n",
       "2  Artificial Intelligence  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_knn_lbl = np.vectorize(reversefactor.get)(pred_knn)\n",
    "\n",
    "test_lines_df['pred_knn'] = pred_knn_lbl\n",
    "test_lines_df['pred_kmeans'] = pred_kmeans\n",
    "test_lines_df['pred_kmeans'] = test_lines_df['pred_kmeans'].map(cluster_label_map)\n",
    "\n",
    "test_lines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
