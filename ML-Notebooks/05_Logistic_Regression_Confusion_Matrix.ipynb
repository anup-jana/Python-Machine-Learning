{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple guide to confusion matrix terminology\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing.\n",
    "\n",
    "Let's start with an <b>example confusion matrix for a binary classifier</b> (though it can easily be extended to the case of more than two classes):\n",
    "\n",
    "| n=165 | <b>Predicted: NO</b> | <b>Predicted: YES</b> |\n",
    "| --- | --- | --- |\n",
    "| <b>Actual: NO</b> | 50 | 10 |\n",
    "| <b>Actual: YES</b> | 5 | 100 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we learn from this matrix?\n",
    "- There are two possible predicted classes: \"yes\" and \"no\". If we were predicting the presence of a disease, for example, \"yes\" would mean they have the disease, and \"no\" would mean they don't have the disease.\n",
    "- The classifier made a total of 165 predictions (e.g., 165 patients were being tested for the presence of that disease).\n",
    "- Out of those 165 cases, the classifier predicted \"yes\" 110 times, and \"no\" 55 times.\n",
    "- In reality, 105 patients in the sample have the disease, and 60 patients do not.\n",
    "\n",
    "Let's now define the most basic terms, which are whole numbers (not rates):\n",
    "- True Positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "- True Negatives (TN): We predicted no, and they don't have the disease.\n",
    "- False Positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "- False Negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")\n",
    "\n",
    "I've added these terms to the confusion matrix, and also added the row and column totals:\n",
    "\n",
    "| n=165 | <b>Predicted: NO</b> | <b>Predicted: YES</b> | Total |\n",
    "| --- | --- | --- | --- |\n",
    "| <b>Actual: NO</b> | TN=50 | FP=10 | 60 |\n",
    "| <b>Actual: YES</b> | FN=5 | TP=100 | 105|\n",
    "| Total | 55 | 110 | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of rates that are often computed from a confusion matrix for a binary classifier:\n",
    "1. <b>Accuracy:</b> Overall, how often is the classifier correct?\n",
    "    - (TP+TN)/total = (100+50)/165 = 0.91\n",
    "2. <b>Misclassification Rate:</b> Overall, how often is it wrong?\n",
    "    - (FP+FN)/total = (10+5)/165 = 0.09\n",
    "    - equivalent to 1 minus Accuracy\n",
    "    - also known as \"Error Rate\"\n",
    "3. <b>True Positive Rate:</b> When it's actually yes, how often does it predict yes?\n",
    "    - TP/actual yes = 100/105 = 0.95\n",
    "    - also known as \"Sensitivity\" or \"Recall\"\n",
    "4. <b>False Positive Rate:</b> When it's actually no, how often does it predict yes?\n",
    "    - FP/actual no = 10/60 = 0.17\n",
    "5. <b>Specificity:</b> When it's actually no, how often does it predict no?\n",
    "    - TN/actual no = 50/60 = 0.83\n",
    "    - equivalent to 1 minus False Positive Rate\n",
    "6. <b>Precision:</b> When it predicts yes, how often is it correct?\n",
    "    - TP/predicted yes = 100/110 = 0.91\n",
    "7. <b>Prevalence:</b> How often does the yes condition actually occur in our sample?\n",
    "    - actual yes/total = 105/165 = 0.64\n",
    "\n",
    "A couple other terms are also worth mentioning:\n",
    "- <b>Positive Predictive Value:</b> This is very similar to precision, except that it takes prevalence into account. In the case where the classes are perfectly balanced (meaning the prevalence is 50%), the positive predictive value (PPV) is equivalent to precision. (More details about PPV: http://en.wikipedia.org/wiki/Positive_and_negative_predictive_values)\n",
    "- <b>Null Error Rate:</b> This is how often you would be wrong if you always predicted the majority class. (In our example, the null error rate would be 60/165=0.36 because if you always predicted yes, you would only be wrong for the 60 \"no\" cases.) This can be a useful baseline metric to compare your classifier against. However, the best classifier for a particular application will sometimes have a higher error rate than the null error rate, as demonstrated by the Accuracy Paradox http://en.wikipedia.org/wiki/Accuracy_paradox.\n",
    "- <b>Cohen's Kappa:</b> This is essentially a measure of how well the classifier performed as compared to how well it would have performed simply by chance. In other words, a model will have a high Kappa score if there is a big difference between the accuracy and the null error rate. (More details about Cohen's Kappa. http://en.wikipedia.org/wiki/Cohen's_kappa)\n",
    "- <b>F Score:</b> This is a weighted average of the true positive rate (recall) and precision. (More details about the F Score. http://en.wikipedia.org/wiki/F1_score)\n",
    "- <b>ROC Curve:</b> This is a commonly used graph that summarizes the performance of a classifier over all possible thresholds. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class. (More details about ROC Curves. http://www.dataschool.io/roc-curves-and-auc-explained/)\n",
    "\n",
    "In relation to Bayesian statistics, the sensitivity and specificity are the conditional probabilities, the prevalence is the prior, and the positive/negative predicted values are the posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression exercise with Titanic data\n",
    "### Introduction\n",
    "- Data from Kaggle's Titanic competition:\n",
    "    - data https://raw.githubusercontent.com/anup-jana/Python-Machine-Learning/master/Datasets/titanic.csv\n",
    "    - data dictionary https://www.kaggle.com/c/titanic/data\n",
    "- Goal: Predict survival based on passenger characteristics\n",
    "- titanic.csv is already in our repo, so there is no need to download the data from the Kaggle website\n",
    "\n",
    "### Step 1: Read the data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/anup-jana/Python-Machine-Learning/master/Datasets/titanic.csv'\n",
    "titanic = pd.read_csv(url, index_col='PassengerId')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create X and y\n",
    "Define <b>Pclass</b> and <b>Parch</b> as the features, and <b>Survived</b> as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['Pclass', 'Parch']\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fit a logistic regression model and examine the coefficients\n",
    "Confirm that the coefficients make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients:\n",
      "('Pclass', -0.88188860564509886)\n",
      "('Parch', 0.34239215857498412)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "model_coef = zip(feature_cols, logreg.coef_[0])\n",
    "print('Model Coefficients:')\n",
    "for values in model_coef:\n",
    "    print(values)  # print each coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make predictions on the testing set and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.668161434978\n"
     ]
    }
   ],
   "source": [
    "# class predictions (not predicted probabilities)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "predicted_class = logreg.predict(X_test)\n",
    "\n",
    "# calculate classification accuracy\n",
    "from sklearn import metrics\n",
    "print('Model Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare your testing accuracy to the null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation Method 1:  0    0.573991\n",
      "Name: Survived, dtype: float64\n",
      "Calculation Method 2:  0.5739910313901345\n"
     ]
    }
   ],
   "source": [
    "# this works regardless of the number of classes\n",
    "print('Calculation Method 1: ', y_test.value_counts().head(1) / len(y_test))\n",
    "\n",
    "# this only works for binary classification problems coded as 0/1\n",
    "print('Calculation Method 2: ', max(y_test.mean(), 1 - y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of Titanic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  23]\n",
      " [ 51  44]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 44\n",
      "True Negatives: 105\n",
      "False Positives: 23\n",
      "False Negatives: 51\n"
     ]
    }
   ],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1][1]\n",
    "TN = confusion[0][0]\n",
    "FP = confusion[0][1]\n",
    "FN = confusion[1][0]\n",
    "\n",
    "print('True Positives:', TP)\n",
    "print('True Negatives:', TN)\n",
    "print('False Positives:', FP)\n",
    "print('False Negatives:', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.463157894737\n",
      "Specifivity:  0.8203125\n"
     ]
    }
   ],
   "source": [
    "# calculate the sensitivity\n",
    "print('Sensitivity: ', TP / float(TP + FN))\n",
    "\n",
    "# calculate the specificity\n",
    "print('Specifivity: ', TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAF3CAYAAABqj7cTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAwSKgGAIBB/x/TxWUzoukUlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc81c630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store the predicted probabilities\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "predicted_probability = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# histogram of predicted probabilities\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "plt.hist(y_pred_prob)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Predicted probability of survival')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Predicted Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.608647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.210461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.391679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.210461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.560828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Class  Predicted Probability\n",
       "0                1               0.608647\n",
       "1                0               0.210461\n",
       "2                0               0.391679\n",
       "3                0               0.210461\n",
       "4                1               0.560828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prdicted Class based on Predicted Probability\n",
    "df = pd.DataFrame({'Predicted Class': predicted_class, 'Predicted Probability': predicted_probability})  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Confusion Matrix: \n",
      " [[105  23]\n",
      " [ 51  44]]\n",
      "\n",
      "New Confusion Matrix: \n",
      " [[105  23]\n",
      " [ 51  44]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression converst probability into class. By default greater than 50% is taken as 1 else 0\n",
    "# Let's test this theory\n",
    "import numpy as np\n",
    "y_pred_class = np.where(y_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# old confusion matrix\n",
    "print('Original Confusion Matrix: \\n', confusion)\n",
    "\n",
    "# new confusion matrix\n",
    "print('\\nNew Confusion Matrix: \\n', metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Confusion Matrix: \n",
      " [[105  23]\n",
      " [ 51  44]]\n",
      "\n",
      "New Confusion Matrix: \n",
      " [[72 56]\n",
      " [32 63]]\n"
     ]
    }
   ],
   "source": [
    "# increase sensitivity i.e. positive rate by lowering the threshold for predicting survival\n",
    "y_pred_class = np.where(y_pred_prob > 0.3, 1, 0)\n",
    "\n",
    "# old confusion matrix\n",
    "print('First Confusion Matrix: \\n', confusion)\n",
    "\n",
    "# new confusion matrix\n",
    "print('\\nNew Confusion Matrix: \\n', metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "new_confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = new_confusion[1][1]\n",
    "TN = new_confusion[0][0]\n",
    "FP = new_confusion[0][1]\n",
    "FN = new_confusion[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sensitivity:  0.663157894737\n",
      "New Specifivity:  0.5625\n"
     ]
    }
   ],
   "source": [
    "# new sensitivity (higher than before)\n",
    "print('New Sensitivity: ', TP / float(TP + FN))\n",
    "\n",
    "# new specificity (lower than before)# new sp \n",
    "print('New Specifivity: ', TN / float(TN + FP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
